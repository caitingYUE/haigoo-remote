import { Job, SyncStatus, RSSSource, SyncError, JobCategory } from '../types/rss-types';
import { rssService } from './rss-service';

// åŸå§‹RSSæ•°æ®æ¥å£
export interface RawRSSData {
  id: string;
  source: string;
  category: string;
  url: string;
  title: string;
  description: string;
  link: string;
  pubDate: string;
  rawContent: string;
  fetchedAt: Date;
  status: 'raw' | 'processed' | 'error';
  processingError?: string;
}

// å¤„ç†åçš„èŒä½æ•°æ®
export interface ProcessedJobData extends Job {
  rawDataId: string; // å…³è”åˆ°åŸå§‹æ•°æ®çš„ID
  processedAt: Date;
  processingVersion: string;
  tags: string[];
  isManuallyEdited: boolean;
  editHistory: {
    field: string;
    oldValue: any;
    newValue: any;
    editedAt: Date;
    editedBy: string;
  }[];
}

// å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
export interface StorageStats {
  totalRawData: number;
  totalProcessedJobs: number;
  storageSize: number; // bytes
  dataRetentionDays: number;
  sources: {
    name: string;
    rawCount: number;
    processedCount: number;
    errorCount: number;
    lastSync?: Date;
  }[];
}

export interface PaginatedResult<T> {
  data: T[];
  total: number;
  page: number;
  pageSize: number;
  totalPages: number;
}

export class DataManagementService {

  private readonly RETENTION_DAYS = 7;

  /**
   * åŒæ­¥æ‰€æœ‰RSSæºæ•°æ® (Backend-driven via SSE)
   * @param skipProcessing æ˜¯å¦è·³è¿‡å¤„ç†æ­¥éª¤ï¼ˆä»…æ‹‰å–åŸå§‹æ•°æ®ï¼‰
   * @param onStatusUpdate å¯é€‰çš„çŠ¶æ€æ›´æ–°å›è°ƒ
   */
  async syncAllRSSData(skipProcessing: boolean = false, onStatusUpdate?: (status: string) => void): Promise<SyncStatus> {
    const syncStatus: SyncStatus = {
      isRunning: true,
      lastSync: new Date(),
      nextSync: null,
      totalSources: 0,
      successfulSources: 0,
      failedSources: 0,
      totalJobsProcessed: 0,
      newJobsAdded: 0,
      updatedJobs: 0,
      errors: []
    };

    if (onStatusUpdate) onStatusUpdate('æ­£åœ¨è¿æ¥æœåŠ¡å™¨å¯åŠ¨åŒæ­¥ä»»åŠ¡...');

    return new Promise((resolve, reject) => {
        // Use daily-ingest task which runs fetch and process in sequence
        // Note: skipProcessing param is currently ignored by the backend daily-ingest task, 
        // which always runs both. We can enhance backend later if needed.
        const eventSource = new EventSource('/api/cron/index?task=daily-ingest');
        
        eventSource.onopen = () => {
            console.log('[Sync] SSE connection opened');
        };

        eventSource.onmessage = (event) => {
            // Generic message handler if needed
        };

        // Listen for specific events
        eventSource.addEventListener('sequence_start', (e: any) => {
            try {
                const data = JSON.parse(e.data);
                if (onStatusUpdate) onStatusUpdate(data.message);
                console.log('[Sync] Sequence Start:', data);
            } catch (err) {}
        });

        eventSource.addEventListener('task_start', (e: any) => {
            try {
                const data = JSON.parse(e.data);
                if (onStatusUpdate) onStatusUpdate(`æ­£åœ¨æ‰§è¡Œ: ${data.task === 'stream-fetch-rss' ? 'æŠ“å–RSS' : 'å¤„ç†æ•°æ®'}`);
                console.log('[Sync] Task Start:', data);
            } catch (err) {}
        });

        eventSource.addEventListener('fetch_complete', (e: any) => {
             try {
                const data = JSON.parse(e.data);
                syncStatus.totalSources = data.fetchedCount || 0; // Approx
                if (onStatusUpdate) onStatusUpdate(data.message);
            } catch (err) {}
        });

        eventSource.addEventListener('save_complete', (e: any) => {
             try {
                const data = JSON.parse(e.data);
                if (data.savedCount) {
                    syncStatus.newJobsAdded += data.savedCount; // Use this for new jobs or raw items depending on context
                }
                if (onStatusUpdate) onStatusUpdate(data.message);
            } catch (err) {}
        });

        eventSource.addEventListener('item_processing', (e: any) => {
             try {
                const data = JSON.parse(e.data);
                if (onStatusUpdate && data.message) onStatusUpdate(data.message);
            } catch (err) {}
        });

        eventSource.addEventListener('error', (e: any) => {
             try {
                const data = JSON.parse(e.data);
                console.error('[Sync] Error:', data);
                syncStatus.errors.push({
                    source: 'Backend',
                    url: '',
                    error: data.message || data.error,
                    timestamp: new Date()
                });
                // Don't close immediately on task error, sequence might continue? 
                // Actually daily-ingest sequence might fail if one task fails.
                // But let's wait for sequence_complete or close on fatal error.
            } catch (err) {}
        });

        eventSource.addEventListener('sequence_complete', (e: any) => {
            try {
                const data = JSON.parse(e.data);
                console.log('[Sync] Sequence Complete:', data);
                if (onStatusUpdate) onStatusUpdate('åŒæ­¥ä»»åŠ¡å…¨éƒ¨å®Œæˆ');
                syncStatus.isRunning = false;
                eventSource.close();
                resolve(syncStatus);
            } catch (err) {
                eventSource.close();
                resolve(syncStatus);
            }
        });

        eventSource.onerror = (err) => {
            console.error('[Sync] SSE Connection Error:', err);
            // Check readyState. If CLOSED (2), it's done.
            if (eventSource.readyState === EventSource.CLOSED) {
                // Already handled
            } else {
                eventSource.close();
                // If we haven't resolved yet
                if (syncStatus.isRunning) {
                    syncStatus.isRunning = false;
                    syncStatus.errors.push({
                        source: 'Connection',
                        url: '',
                        error: 'è¿æ¥ä¸­æ–­',
                        timestamp: new Date()
                    });
                    reject(new Error('SSE Connection Error'));
                }
            }
        };
    });
  }

  /**
   * è·å–åŸå§‹RSSæ•°æ®ï¼ˆåˆ†é¡µæŸ¥è¯¢ï¼‰
   */
  async getRawData(page: number = 1, pageSize: number = 50, filters?: {
    source?: string;
    category?: string;
    status?: 'raw' | 'processed' | 'error';
    dateRange?: { start: Date; end: Date };
  }): Promise<PaginatedResult<RawRSSData>> {
    try {
      // æ„å»ºæŸ¥è¯¢å‚æ•°
      const queryParams = new URLSearchParams();
      queryParams.append('page', page.toString());
      queryParams.append('limit', pageSize.toString());

      // æ·»åŠ è¿‡æ»¤å™¨å‚æ•°
      if (filters?.source) queryParams.append('source', filters.source);
      if (filters?.category) queryParams.append('category', filters.category);
      if (filters?.status) queryParams.append('status', filters.status);
      
      // å¤„ç†æ—¥æœŸèŒƒå›´
      if (filters?.dateRange) {
        queryParams.append('dateFrom', filters.dateRange.start.toISOString().split('T')[0]);
        queryParams.append('dateTo', filters.dateRange.end.toISOString().split('T')[0]);
      }

      // æ·»åŠ æ—¶é—´æˆ³é¿å…ç¼“å­˜
      queryParams.append('_t', Date.now().toString());

      // è°ƒç”¨åç«¯APIè¿›è¡ŒçœŸæ­£çš„åˆ†é¡µæŸ¥è¯¢
      const resp = await fetch(`/api/data/raw-rss?${queryParams.toString()}`);
      if (!resp.ok) {
        throw new Error(`GET /api/data/raw-rss failed: ${resp.status}`);
      }

      const result = await resp.json();
      
      // è½¬æ¢åç«¯APIè¿”å›çš„æ•°æ®æ ¼å¼ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
      return {
        data: result.items || [],
        total: result.total || 0,
        page: result.page || page,
        pageSize: result.pageSize || pageSize,
        totalPages: result.totalPages || 0
      };
    } catch (error) {
      console.error('è·å–åŸå§‹æ•°æ®å¤±è´¥:', error);
      return {
        data: [],
        total: 0,
        page,
        pageSize,
        totalPages: 0
      };
    }
  }

  /**
   * è·å–å¤„ç†åçš„èŒä½æ•°æ®ï¼ˆåˆ†é¡µæŸ¥è¯¢ï¼‰
   */
  async getProcessedJobs(page: number = 1, pageSize: number = 50, filters?: {
    id?: string;
    category?: string;
    source?: string;
    experienceLevel?: string;
    isManuallyEdited?: boolean;
    isFeatured?: boolean;
    isApproved?: boolean;
    company?: string;
    industry?: string;
    // æ–°å¢ï¼šå…³é”®è¯æœç´¢ï¼ˆå²—ä½åç§°/å…¬å¸/æè¿°/åœ°ç‚¹/æ ‡ç­¾ï¼‰
    search?: string;
    isRemote?: boolean;
    location?: string;
    tags?: string[];
    dateRange?: { start: Date; end: Date };
    sortBy?: string;
  }): Promise<PaginatedResult<ProcessedJobData>> {
    try {
      // æ„å»ºæŸ¥è¯¢å‚æ•°
      const queryParams = new URLSearchParams();
      queryParams.append('page', page.toString());
      queryParams.append('limit', pageSize.toString());

      // æ·»åŠ è¿‡æ»¤å™¨å‚æ•°
      if (filters?.id) queryParams.append('id', filters.id);
      if (filters?.category) queryParams.append('category', filters.category);
      if (filters?.source) queryParams.append('source', filters.source);
      if (filters?.company) queryParams.append('company', filters.company);
      if (filters?.industry) queryParams.append('industry', filters.industry);
      if (filters?.location) queryParams.append('location', filters.location);
      if (filters?.search) queryParams.append('search', filters.search);
      if (filters?.isRemote !== undefined) queryParams.append('isRemote', filters.isRemote.toString());
      if (filters?.isApproved !== undefined) queryParams.append('isApproved', filters.isApproved.toString());
      if (filters?.isFeatured !== undefined) queryParams.append('isFeatured', filters.isFeatured.toString());
      if (filters?.sortBy) queryParams.append('sortBy', filters.sortBy);
      if (filters?.tags && filters.tags.length > 0) queryParams.append('tags', filters.tags.join(','));
      
      // å¤„ç†æ—¥æœŸèŒƒå›´
      if (filters?.dateRange) {
        queryParams.append('dateFrom', filters.dateRange.start.toISOString().split('T')[0]);
        queryParams.append('dateTo', filters.dateRange.end.toISOString().split('T')[0]);
      }

      // æ·»åŠ æ—¶é—´æˆ³é¿å…ç¼“å­˜
      queryParams.append('_t', Date.now().toString());

      // Get token for admin access
      const token = localStorage.getItem('haigoo_auth_token');
      const headers: HeadersInit = {};
      if (token) {
        headers['Authorization'] = `Bearer ${token}`;
      }

      // è°ƒç”¨åç«¯APIè¿›è¡ŒçœŸæ­£çš„åˆ†é¡µæŸ¥è¯¢
      const resp = await fetch(`/api/data/processed-jobs?${queryParams.toString()}`, {
        headers
      });
      if (!resp.ok) {
        throw new Error(`GET /api/data/processed-jobs failed: ${resp.status}`);
      }

      const result = await resp.json();
      
      // è½¬æ¢åç«¯APIè¿”å›çš„æ•°æ®æ ¼å¼ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
      return {
        data: result.jobs || [],
        total: result.total || 0,
        page: result.page || page,
        pageSize: result.pageSize || pageSize,
        totalPages: result.totalPages || 0
      };
    } catch (error) {
      console.error('è·å–å¤„ç†åæ•°æ®å¤±è´¥:', error);
      return {
        data: [],
        total: 0,
        page,
        pageSize,
        totalPages: 0
      };
    }
  }

  /**
   * æ·»åŠ æ–°çš„å¤„ç†åèŒä½
   */
  async addProcessedJob(job: ProcessedJobData): Promise<boolean> {
    try {
      job.isManuallyEdited = true;
      job.updatedAt = new Date().toISOString();
      await this.saveProcessedJobs([job], 'append');
      return true;
    } catch (error) {
      console.error('æ·»åŠ èŒä½å¤±è´¥:', error);
      return false;
    }
  }

  /**
   * æ›´æ–°å¤„ç†åçš„èŒä½æ•°æ®
   */
  async updateProcessedJob(jobId: string, updates: Partial<ProcessedJobData>, editedBy: string = 'admin'): Promise<boolean> {
    try {
      // ä¼˜åŒ–ï¼šä»…è·å–éœ€è¦æ›´æ–°çš„èŒä½ï¼Œè€Œä¸æ˜¯å…¨éƒ¨åŠ è½½
      const result = await this.getProcessedJobs(1, 1, { id: jobId });
      
      if (result.data.length === 0) {
        return false;
      }

      const currentJob = result.data[0];
      const updatedJob = { ...currentJob };
      
      // Ensure editHistory exists
      if (!updatedJob.editHistory) {
        updatedJob.editHistory = [];
      }

      // è®°å½•ç¼–è¾‘å†å²
      Object.keys(updates).forEach(field => {
        if (field !== 'editHistory' && updates[field as keyof ProcessedJobData] !== currentJob[field as keyof ProcessedJobData]) {
          updatedJob.editHistory.push({
            field,
            oldValue: currentJob[field as keyof ProcessedJobData],
            newValue: updates[field as keyof ProcessedJobData],
            editedAt: new Date(),
            editedBy
          });
        }
      });

      // åº”ç”¨æ›´æ–°
      Object.assign(updatedJob, updates);
      updatedJob.isManuallyEdited = true;
      updatedJob.updatedAt = new Date().toISOString();

      // ä½¿ç”¨ append æ¨¡å¼è¿›è¡Œå¢é‡æ›´æ–° (Upsert)ï¼Œé¿å…è¦†ç›–å…¶ä»–æ•°æ®
      await this.saveProcessedJobs([updatedJob], 'append');

      return true;
    } catch (error) {
      console.error('æ›´æ–°èŒä½æ•°æ®å¤±è´¥:', error);
      return false;
    }
  }

  /**
   * åˆ é™¤å¤„ç†åçš„èŒä½
   */
  async deleteProcessedJob(jobId: string): Promise<boolean> {
    try {
      const resp = await fetch(`/api/data/processed-jobs?id=${encodeURIComponent(jobId)}`, {
        method: 'DELETE'
      });

      if (!resp.ok) {
        throw new Error(`DELETE failed: ${resp.status}`);
      }

      return true;
    } catch (error) {
      console.error('åˆ é™¤èŒä½å¤±è´¥:', error);
      return false;
    }
  }

  /**
   * æ¸…é™¤æ‰€æœ‰å¤„ç†åçš„èŒä½æ•°æ®
   */
  async clearAllProcessedJobs(): Promise<boolean> {
    try {
      // Send explicit clear request to backend
      const resp = await fetch('/api/data/processed-jobs', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ jobs: [], mode: 'replace' })
      });

      if (!resp.ok) {
        const text = await resp.text();
        throw new Error(`Failed to clear jobs: ${resp.status} ${text}`);
      }

      console.log('å·²æ¸…é™¤æ‰€æœ‰å¤„ç†åçš„èŒä½æ•°æ®');
      return true;
    } catch (error) {
      console.error('æ¸…é™¤èŒä½æ•°æ®å¤±è´¥:', error);
      return false;
    }
  }

  /**
   * é‡æ–°å¤„ç†æ‰€æœ‰èŒä½çš„URL (Deprecated)
   * Functionality should be moved to backend
   */
  async reprocessJobUrls(): Promise<{ updated: number }> {
    console.warn('reprocessJobUrls is deprecated and disabled in frontend. Please implement backend task.');
    return { updated: 0 };
  }

  /**
   * è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
   */
  async getStorageStats(): Promise<StorageStats> {
    try {
      // ä¼˜å…ˆä»åç«¯APIè¯»å–çœŸå®ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ¥æºKVï¼‰
      const resp = await fetch(`/api/data/processed-jobs?action=stats&_t=${Date.now()}`);
      if (!resp.ok) throw new Error(`GET /api/data/processed-jobs?action=stats failed: ${resp.status}`);
      const stats = await resp.json();

      const sources = rssService.getRSSSources();
      const sourceStats = sources.map(source => ({
        name: `${source.name} - ${source.category}`,
        rawCount: 0,
        processedCount: 0,
        errorCount: 0,
        lastSync: stats?.lastSync ? new Date(stats.lastSync) : undefined
      }));

      return {
        totalRawData: 0,
        totalProcessedJobs: Number(stats?.totalJobs || 0),
        storageSize: Number(stats?.storageSize || 0),
        dataRetentionDays: this.RETENTION_DAYS,
        sources: sourceStats
      };
    } catch (error) {
      console.warn('APIè·å–å­˜å‚¨ç»Ÿè®¡å¤±è´¥:', error);
       return {
          totalRawData: 0,
          totalProcessedJobs: 0,
          storageSize: 0,
          dataRetentionDays: this.RETENTION_DAYS,
          sources: []
        };
    }
  }

  /**
   * æ¸…ç†è¿‡æœŸæ•°æ®
   */
  private async cleanupOldData(): Promise<void> {
    try {
      console.log('ğŸ§¹ å¼€å§‹æ¸…ç†è¿‡æœŸæ•°æ® (è°ƒç”¨åç«¯API)...');
      
      const sources = rssService.getRSSSources().map(s => s.name);

      const resp = await fetch(`/api/data/processed-jobs?action=cleanup&days=${this.RETENTION_DAYS}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ sources })
      });
      
      const result = await resp.json();
      if (resp.ok && result.success) {
        console.log(`ğŸ§¹ æ¸…ç†å®Œæˆ: åˆ é™¤äº† ${result.deleted} ä¸ªè¿‡æœŸèŒä½`);
      } else {
        console.warn('æ¸…ç†è¿‡æœŸæ•°æ®è­¦å‘Š:', result.error || 'æœªçŸ¥é”™è¯¯');
      }
      
    } catch (error) {
      console.error('æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥:', error);
    }
  }

  // ç§æœ‰è¾…åŠ©æ–¹æ³•
  private async saveProcessedJobs(jobs: ProcessedJobData[], mode: 'append' | 'replace' = 'append'): Promise<void> {
    try {
      // åˆ†ç‰‡ä¸Šä¼ ï¼Œé¿å… 413ï¼ˆè¯·æ±‚ä½“è¿‡å¤§ï¼‰
      const CHUNK_SIZE = 200;
      for (let i = 0; i < jobs.length; i += CHUNK_SIZE) {
        const chunk = jobs.slice(i, i + CHUNK_SIZE);
        // å¦‚æœæ˜¯ 'replace' æ¨¡å¼ï¼Œåªæœ‰ç¬¬ä¸€æ‰¹æ¬¡ä½¿ç”¨ 'replace'ï¼ˆæ¸…ç©ºæ—§æ•°æ®ï¼‰ï¼Œåç»­æ‰¹æ¬¡ä½¿ç”¨ 'append'
        const chunkMode = (mode === 'replace' && i > 0) ? 'append' : mode;
        
        const resp = await fetch('/api/data/processed-jobs', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ jobs: chunk, mode: chunkMode })
        })
        if (!resp.ok) {
          const text = await resp.text()
          throw new Error(`POST /api/data/processed-jobs failed: ${resp.status} ${text}`)
        }
      }
    } catch (error) {
      console.error('ä¿å­˜å¤„ç†åæ•°æ®åˆ°APIå¤±è´¥:', error)
      throw error
    }
  }

}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const dataManagementService = new DataManagementService();
